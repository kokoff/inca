\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{lipsum} %This package just generates Lorem Ipsum filler text. 
\usepackage{fullpage} % changes the margin
\usepackage{graphicx}
 \usepackage{cite}
 \usepackage{appendix}
 
 \usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}

\usepackage{csvsimple}
\usepackage{pgfplotstable}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning,matrix}
\usepackage{neuralnetwork}
\usepackage{tikz}
%\usetikzlibrary{...}
\usepackage{standalone}
\usepackage{subcaption}

\usepackage[font={small,it}]{caption}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.7em}

\usepackage{titlesec}
\titlespacing\section{0pt}{11pt }{-3pt}
\titlespacing\subsection{0pt}{10pt}{-3pt}
\titlespacing\subsubsection{0pt}{10pt}{-3pt}

\begin{document}

\title{Introduction to Neural Computing and Applications (INCA)
Open Examination}
\author{Exam Number: Y1403115}
\date{}
\maketitle


\part*{Section A}
\section{Architecture Discussion}

\subsection{Problem}
The problem is a two class classification problem - occupancy detection based on sensor readings. The data includes sensor readings for temperature, humidity, light and carbon dioxide. An additional feature, humidity ratio, was derived from the original recorded variables. Each point in the data set is also timestamped. In \cite{Candanedo2016} the time stamp was used to derive two additional features - week status(WS) and number of seconds from midnight(NSM).

A certain amount of noise is expected in the recorded data so a suitable architecture should have good generalisation. Since data was measured in a controlled environment we expect the range of training variables to roughly match the range of expected new data.

\subsection{Architectures}
There are several neural network architectures suitable for this kind of classification problem. We will consider Multilayer perceptron and Radial basis function network. 
\subsubsection{Multilayer Perceptron (MLP)}
MLP is a feedforward neural network with multiple neurons composed in multiple layers. All neurons are the same in the case of classification and they compute a weighted sum of inputs and apply an activation function (sigmoid or tanh). There is an input layer, which distributes the inputs, one or more hidden layers and an output layer. Each layer feeds into the next one. This type of neural network uses an error correcting learning rule and a backpropagation training algorithm. Backpropagation consists of two stages - a forward pass, where outputs are computed, and a backward pass, where weights are adjusted according to the error in outputs. In the backward pass the output layer weights are adjusted according to the local gradient of the error function and the hidden layer weights are adjusted according to the local gradients of the nodes in the subsequent layer. 
\subsubsection{MLP Advantages and disadvantages}
The multilayer perceptron is suitable for non-linearly separable classification problems. Once a good approximate solution is found, generalisation can be easily improved by adjusting the stopping criteria of the training algorithm or by using regularisation. MLP is a global approximator (because it splits the entire pattern space using lines), which can be an advantage if we expect abnormal data points in unseen data and want to try to classify them. 

On the other hand, determining the number of hidden layers and the number of neurons in each layer may require a lot of experimentation. Also the training algorithm uses local gradients and can often get stuck in a local minimum of the error function. 


%MLP is a feedforward, multilayer architecture consisting of one input layer, one output layer and hidden layers. The input layer just passes on the inputs. Each neuron in the hidden layers computes a weighted sum of inputs, applies a transfer function and passes it's output to each neuron in the next layer. Each layer feeds into the next and the output layer produces the outputs. The MLP uses an error correction learning rule, where it minimises an error function defined by the difference of it's output and the desired output (typically the error function is mean squared error). In order to minimise the error function, it needs to be continuous, therefore the transfer function of each neuron is either a hyperbolic tangent function or a sigmoid function. The training algorithm for MLP is backpropagation. It consists of a forward pass, where the network computes it's output and a backward pass, where the weights are adjusted. Weight changes at each layer are computed based on the local gradient of the next layer. The MLP classifies patterns by partitioning the feature space into regions. It can be used to solve linearly inseparable classification problems, as each layer computes a non-linear transformation of the outputs of the previouse one.
\subsubsection{Radial Basis Function Network (RBFN)}
RBFN is a feedforward neural network, consisting of single hidden layer, an input and an output layer. The input layer just distributes inputs to the hidden layer. Each neuron in the hidden layer computes a radially symmetric basis activation function (typically a Gaussian) from the inputs. The output layer neurons compute a weighted sum of the outputs of the hidden layer. Each neuron in the hidden layer has two associated parameters - a point in the feature space, which is called a center, and a spread. It computes its response to a given input based on the euclidean distance between the data point and its center. Training is typically done in two stages - center selection and weight estimation (weights are computed in a single matrix vector calculation). RBFNs can also be trained in a supervised manner (like MLP) or by selecting centres at each data point and using regularisation, but these approaches are much slower.
\subsubsection{RBFN Advantages and Disadvantages}
There is just one hidden layer so only its size needs to be determined experimentally. When using unsupervised center selection, weights can be computed in a single calculation. In comparison to MLP, in RBFN there are far less architecture parameters, which need to be varied, when searching for an architecture. The RBFN is a local approximator. This is an advantage when we expect new data to be in a similar range to the training data or when abnormal inputs need to be classified into one class. 

It is difficult to determine center locations. When data is not tightly clustered, the network might need a very large hidden layer.  Supervised center selection and regularisation training approaches are very slow. 

%\subsubsection{Correlation Matrix Memory(CMM)}
%CMMs are single layer neural networks, which use the Hebbian learning rule. They consist of a single weight matrix which stores correlations between input and output patterns. Learning is done by computing the outer product of the input and output and adding it to the outer products of all other patterns to form the weight matrix. Recall of a stored pattern is done by multiplying the weight matrix and the input. For efficiency these networks usually have binary inputs and weights. In order to use a CMM as a classifier the output needs to be threasholded, so the highest output value is set to 1 and represents the class, or some kind of postprocessing needs to be done such as the one used in \cite{Zhou1998}.  
%\subsubsection{CMM advantages and disadvantages}
%A hardware implementation of CMM can be very fast. Training and recall are both very fast operations. \\
%A CMM can store a limited number of pattern associations after which new associations become diluted. Real valued data needs to be encoded using a binning algorithm. Best performance requires input patterns to follow a uniform distribution. Good classification might require additional post processing (e.g. k nearest neighbours).

%\subsubsection{Advantages/Disadvantages}
%The Perceptron is a very simple and quick to train network consisting of a single neuron. However it can easily be ruled out because of it's inability to classify linearly inseperable problems. From figure \ref{fig:plotmatrix} we can clearly see that our data is linearly inseperable when looking at the relation between Hummidity and CO2 for example. 
%The MLP is suatable for solving non-linearly seperable problems. It's iterative training process can be slow depending on the error function minimisation method used, however it is very customisable. Once a good aproximate solution is found generalisation can be easyly improved by adjusting the stopping criteria of the training or employing regularisation. Choosing the right size of the network might require a lot of trial and error. The MLP is global aproximator, which might be an advantage when we could expect new data to be significantly different from training data.
%The RBFN has a single hidden layer. Training can be very slow when using supervised selection of centers or regularisation. There are much less architecture parameters that can be varied when searching for a suitable architecture compared to the MLP. The RBFN is a local aproximator, which is an advantage when we expect new data to be in a similar range to the training data and can also be used for detecting abnormal inputs. 

%\subsection{Data exploration}
%All features - Temperature, Humidity, Light, CO2, Humidity Ratio are real valued. In figure \ref{fig:plotmatrix} the MATLAB $gplotmatrix$ function is used to plot all variables against each other and create histograms of each variable along the diagonal and class are color coded.  

\subsubsection{Choice of network architecture}
Comparing the two architectures described above, we choose an RBFN network architecture. Compared to the MLP the RBFN has a simpler training process. Furthermore, using our knowledge of the problem we can see that the range of data we have should more or less match the expected range of unseen data, because the deployment environment is controlled. This means a local classifier would be more suitable than an global classifier. There are far less training parameters that have to be discovered experimentally when using an RBFN.

\section{Creation and Application}

\subsection{Data}
%• Data [10 marks]
%Describe (briefly) the data you have, and how much there is of it.
%Describe the inputs to (and outputs from) the network. You need to
%describe how the data you started with have been preprocessed. Explain
%how you investigated the data, including any assumptions you have
%made. Again, this may include some testing of networks to see what the
%effects are of different preprocessing choices. Give a step by step process
%for transforming the data into the network inputs, sufficient for someone
%else to process a new batch of data for use with the trained network. If
%you have transformed inputs using PCA, give the transformation matrix
%as an appendix to the report.
Three data sets are provided for training, validation and testing. The test sets are merged together in chronological order of the timestamps. This composite data set has 20,560 data points. The timestamps themselves are not used as features. The features used are Temperature, Humidity, Light, CO2, and Humidity Ratio and all of them are real valued. The target outputs are binary. Hummidity Ratio is not a sensor reading but it has been derived from Humidity measurements \cite{Candanedo2016}.

In figure \ref{fig:plotmatrix} the MATLAB $gplotmatrix$ function is used to plot all input variables against each other and to create histograms of each variable along the diagonal (classes are color coded). We can make several observations based on this plot. The plots of Light against all other features show a clear separation of the two classes, so Light is probably an important feature. On the other hand, the histogram of Light is bimodal and clearly the examples around the second peak are much less than around the first, which means they are under-represented and might not be properly incorporated in the model. Looking at CO2 we see that it's distribution is skewed, which also might cause problems for our model. The other distributions of variables look normal. 

\begin{figure}[h]
  \centering
    \includegraphics[width=1\textwidth]{../figures/plotmatrix.png}
	\caption{Plot matrix}    
    \label{fig:plotmatrix}
\end{figure}


There seems to be a big correlation between Hummidity and HummidityRatio, which makes sense since the latter is derived from the first one. It might be a good idea to discard HummidityRatio. However to make sure that we are really removing unimportant features and to be able to measure their contribution to the dataset we use Principal component analysis (PCA). PCA does two things. It orthogonalises input components to remove correlation between them. It can also be used measure components contribution to total variance of the data set and make a decision to remove principal components which have little contribution. Since PCA is sensitive to big variances in the data, we first preprocess the data to have a variance of 1 (using Matlab $mapstd$ function) and then we apply PCA (Matlab $pca$ function). PCA gives us the eigenvectors and eigenvalues of the covariance matrix of the data. The eigenvectors are the transformed inputs (principal components) and the eigenvalues tell us how much each component contributes to the overall variance. Looking at figure \ref{fig:eigenvalues} we can see that the eigenvalue for the fifth principal component is only 0.001 and in terms of percentage, the contribution of this component to overall variance is 0.03\%. This means that the fifth principal component hardly has any contribution on the variance of the data. Removing it wouldn't affect the separability of the data but might make network training more efficient. The forth principal component has a much greater contribution to overall variance (6.3\%) so we decide keep it. The threshold for eigenvalues of principal components has to be between the value of the forth and fifth. We decide to set it at 0.02.


Furthermore, looking at figure \ref{fig:pca_plotmatrix} we see that the distributions of all 4 principal components are nearly normal, which means we don't have to worry about potential problems arising from the skewed CO2 distribution or the asymmetric bimodal distribution of Light.

\begin{figure}[h]
  	\centering
    \includegraphics[width=1\textwidth]{../figures/eigenvalues.png}
    \caption{Eigenvalues and percent contribution to overall variance of each principal components}
    \label{fig:eigenvalues}
\end{figure}


\begin{figure}[h]
  	\centering
    \includegraphics[width=0.5\textwidth]{../figures/pca_plotmatrix.png}
    \caption{Plot matrix of principal components}
	\label{fig:pca_plotmatrix}
\end{figure}


In the end, preprocessing of the input data consist of normalising variances of features to 1. And applying a transformation using principal component analysis, removing principal components with eigenvalues less than 0.02. We use the Matlab functions $x1, trans1 = mapstd(x)$ and $x2, trans2 = processpca(x1, 0.02)$. The transformation settings $trans1$ and $trans2$(including transformation matrices) are provided in the appendix in table \ref{table:mapstd} and table \ref{table:pca}.
  


\subsection{Network}
\begin{figure}[h]
\centering
  \includestandalone[width=0.5\textwidth]{diagram}%     without .tex extension
  % or use \input{mytikz}
  \caption{RBFN architecture diagram.}
  \label{fig:architecture}
\end{figure}

%You should describe the network architecture that you have found to
%be the best for solving the problem. The description of the structure of the architecture should be sufficient for someone else to implement your
%network exactly, and not necessarily using MATLAB, so you should
%include all the structural information and parameters necessary. Include
%a diagram.
%You should also indicate how you implemented it. This could be brief if
%you have used MATLAB defaults, for example.
\subsubsection{Inputs}
Inputs are preprocessed before they are presented to the network. The data set is then randomly split into a training set and a test set with ratio 75\%/25\%.

\subsubsection{Input Layer}
The input layer distributes inputs, after preprocessing, to each neuron in the hidden layer. The size of the input layer is therefore the size of the input vector $N=4$ (after PCA). It is fully connected to the hidden layer.

\subsubsection{Hidden Layer}
There is a single hidden layer fully connected to the output layer. The optimal size of the hidden layer found by experimentation is $M=20$. The activation function of each neuron is an isotropic Gaussian:

\begin{equation}
\Phi_i(\boldsymbol{x}) = \exp\left(-\frac{1}{2\sigma^2} \lvert\lvert \boldsymbol{x} -  \boldsymbol{c_i} \rvert\rvert ^2\right)
\quad \mathrm{where }\quad
\sigma^2 = \frac{1}{2}(\epsilon \times d_{max})^2
\label{eq:rbf}
\end{equation}


Where $m$ is the number of hidden neurons (number of centres), $d_{max}$ is the maximum distance between centres, $\epsilon$ is a parameter used to vary the spread of the Gaussian ($0<\epsilon<2$) and $\boldsymbol{c_i}$ is the center vector of neuron $i$. The centres for each hidden layer neuron are found using a k-means clustering algorithm. The number of centres $\boldsymbol(c_i)$ and spread parameter $\epsilon$ were found through experimentation.

\subsubsection{Output Layer}
The output layer calculates a weighted sum of hidden layer outputs:

\begin{equation}
y(\boldsymbol{x}) = \displaystyle\sum_{i=1}^{m} w_i \Phi_i(\boldsymbol{x})
\end{equation}


In order to obtain hard classification output, a threshold is applied to $y(\boldsymbol{x})$ - if $y>0.5$ output is 1, else output is 0. The outputs use a boolean encoding, where 1 signifies occupancy.

\subsubsection{Best found architecture}
The best architecture found through experimentation uses the k-means algorithm to find center locations. The experimentally discovered parameter values are $m = 20, \epsilon = 0.8$. The network architecture and parameters are given below in table \ref{table:architecture}.

\begin{table}[h!]
\centering
\begin{tabular}{|l l|} 
 \hline
 Network type & Radial basis function network  \\ 
 \hline
 Data features/inputs & Temperature, Humidity, Light, CO2, HumidityRatio\\
 Data preprocessing & Normalize standard deviation to 1 \\
 & Principal component analysis (PCA) \\
 PCA variance threshold & 0.02 \\ 
 Data train/test set split & Random 75\%/25\% \\
 \hline
 Hidden layer activation function (RBF) & $
\Phi_i(\boldsymbol{x}) = \exp\left(-\frac{1}{(\epsilon \times d_{max})^2} \lvert\lvert \boldsymbol{x} -  \boldsymbol{c_i} \rvert\rvert ^2\right)  
$  \\
 Hidden layer size ($m$) & 20  \\
 RBF spread $\sigma^2$ & $\frac{1}{2}(0.8 \times d_{max})^2$   \\
 \hline
 Output layer activation function & Linear: $y(\boldsymbol{x}) = \displaystyle\sum_{i=1}^{m} w_i \Phi_i(\boldsymbol{x})$ \\
 Output layer size & 1 \\
 \hline
 Training algorithm & 1. Unsupervised center selection \\ 
 & 2. One step weight calculation using matrix pseudo inverse  \\
 Centre selection algorithm & k-means clustering \\
 Performance function & Mean Squared Error (MSE)  \\ [1ex] 
 \hline
\end{tabular}
\caption{Best found RBFN architecture.}
\label{table:architecture}
\end{table}

\subsubsection{Implementation}
The RBF network was implemented in Matlab, following the solution from practical sessions. The code is given in the appendix (RBFN.m). For performing experiments(rerunning network several times with different parameters) an additional script was used. It is also provided in the appendix (runRBFN.m)


\subsection{Training}
%Explain how you selected the best training algorithm for this problem.
%This could include testing different networks and training algorithms to
%see what might work well.
%For the training algorithm you used with the final version of the network,
%give sufficient detail for someone to implement the training algorithm.
%This does NOT mean (for example) describe gradient descent in great
%detail. It DOES mean give any parameters, initialisation, etc, even if
%they are the toolbox defaults.
Three types of RBFN training algorithms were considered - regularisation with number of hidden neurons equal to the number of data points, supervised center selection and unsupervised center selection. Unsupervised center selection was chosen out of the three because of it's performance in terms of speed. Unsupervised center selection is a two step training algorithm. The first step is selecting the center points for each hidden neuron. The second step is  calculating the output layer weights based on the outputs of the hidden layer, minimising an error function (MSE in this case). After having selected the center points and preprocessed the data, the training algorithms goes through the following steps, assuming center points are in a matrix $c$, preprocessed training data is in a matrix $x$, the target data is stored in a binary vector $D$ and the predefined number of centres is $m$:
\begin{list}{•}{•}
\item[1] Calculate the euclidean distance from each of the centres (columns of $c$) to each of the data points (columns in $x$) and store them in a matrix $distance$. Calculate the distances from every centre to every centre and store them in a matrix $dc$.  
\item[2] Find the maximum center to center distance and store it in $d_{max}$. $d_{max}$ is then used to calculate the spread of all radial basis functions in the hidden layer: $\sigma^2 = \frac{1}{2}(\epsilon \times d_{max})^2$, where $\epsilon$ is a user defined parameter. 
\item[3] Calculate a matrix of responses from each basis function to each data point. Using equation \ref{eq:rbf} this calculation would be:
\begin{equation}
F = \Phi_i(\boldsymbol{x}) = \exp\left(-\frac{m}{(\epsilon \times d_{max})^2} distances^2 \right)  
\end{equation}
\item[4] Calculate the weights of the output layer $W$ using the pseudo inverse of $F$, $F^+$ and the target data $D$: $W= F^+D$.
\end{list}


For the center selection step, of the training algorithm, two options were considered - random center selection and k-means clustering. The kmeans function from Matlab was used for the k-means clustering approach, which uses k-means++ algorithm \cite{Arthur2007} for generating initial center locations and then runs the k-means clustering algorithm \cite{Lloyd82} to iteratively search for the true center locations. In order to decide between random center selection and k-means, an experiment was performed.  The experiment compared two networks, structurally the same as the one in table \ref{table:architecture}, but with number of centres $m = 10, 15, 20, 25$ and $\epsilon = 1$. The two networks use the two different center selection algorithms(random vs k-means). They were ran 10 times for each parameter combination and mean performance values were recorded. The results are given below in table \ref{table:centermse}

\begin{table}[h]
\centering
\begin{tabular}{| l | l | l | l | l | l |}
\hline
Number of centres (m) & 10 & 15 & 20 & 25 \\
\hline
Random center selection Test MSE mean & 0.0735 & 0.0785 & 0.0832 & 0.0649 \\
\hline
Random center selection Test MSE Std & 0.0306 & 0.0523 & 0.0499 & 0.0304 \\
\hline
K-means Test MSE mean & 0.0331 & 0.0237 & 0.0190 & 0.0187 \\
\hline
K-means Test MSE Std & 0.0032 & 0.0044 & 0.0043 & 0.0041 \\
\hline
\end{tabular}
\caption{Performance results for random centre selection and k-means}
\label{table:centermse}
\end{table}


Clearly the performance (in terms of MSE) of k-means is much better than random center selection. So this is the algorithm we will use.

\subsection{Evaluation}
%In selecting the final network you will have to make choices about, for
%example, the number of neurons or the number of layers to use.
%– Explain what metric or metrics you used for comparison between
%networks.
%– Explain the process you went through in making the selection of
%the final architecture. If you evaluated a number of networks, give
%details of what their structures were and how they performed. You
%may summarise repeated tests of the same structure, but remember
%to give mean and variance of summary statistics.
%– Explain how you used the data in this selection process. For example,
%was it split into training, validation and test sets? How big were
%they?
We have already discussed decisions about the network structure, training algorithm, data preprocessing and splitting into training and test sets. The rest of the parameters were discovered experimentally. They are the number of centres (size of hidden layer) and basis function spread parameter $\epsilon$.
\subsubsection{Metrics}
MSE was used as a metric of performance. However MSE on it's own was not sufficient. It keeps decreasing as we increase the number of nodes in the network and two many nodes could lead to poor generalisation. This is why in addition to MSE, we also looked at the percentage of errors in each of the two classes to help us evaluate performance. Ideally the model should be unbiased and make an approximately equal amount of errors in both classes. If the model develops a bias against a particular class this means that we are probably overfitting or not capturing the structure of the data.



\subsubsection{Experimentation for determining final network}
Initially we fix $\epsilon$ and only vary the number of centres $m$, searching for networks with low MSE and approximately equal percentage of errors in both classes. We set the spread parameter $\epsilon = 1$ and run for different hidden layer sizes $m = 5, 10, 15, 20, 25, 30, 40, 50, 60$. For each value of $m$ we train and evaluate the network 10 times and record the mean value of MSE, mean percentage of errors and mean absolute difference of errors for both the training and test sets. Results are plotted in figure \ref{fig:performance}.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/perf/mseplot_m(5-60)_e(10-10).png}
        \caption{Mean MSE of Test and Train sets.}
        \label{fig:mse}
    \end{subfigure}
    \hfill %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/perf/errorplot_m(5-60)_e(10-10).png}
        \caption{Mean absolute difference of errors in class 0 and class 1 and mean percentage of errors in both classes, measured on test set.}
        \label{fig:errorplot}
    \end{subfigure}
    \hfill %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/perf/errorbar_m(5-60)_e(10-10).png}
        \caption{Bar plot of mean percentage of errors in class 0 and class 1 measured on test set.}
        \label{fig:errorbar}
    \end{subfigure}
    \caption{Performance of RBFN with parameters $m = 5,15,20,25,30,40,50,60$ and $\epsilon = 1$, ran 10  times for each parameter combination.}\label{fig:performance}
\end{figure}


From figure \ref{fig:mse} we can see that the MSE decreases when increasing the number of nodes, as we expected. After 20 hidden nodes, the MSE decreases at a smaller rate. Looking at figure \ref{fig:errorplot} we see that after around 20 hidden nodes, the mean absolute difference in errors doesn't change very much and the total number of errors decreases at a very small rate. These two plots give us an understanding of how error decreases as we increasing number of neurons, but tells us little about how much we are overfitting the data. Looking at figure \ref{fig:errorbar} we can see that after 25 hidden nodes the errors in class 1 remain the same, while the errors in class 0 decrease. After that point the network is developing a bias against class 0. This is a hint that we are overfitting. On the other hand, when we use fewer than 20 nodes the bias of the network is against the other class. This probably means we don't have enough neurons to capture the structure of the data. We decide to use 20 hidden nodes in the hidden layer. We perform more experiments to determine the spread coefficient $\epsilon$, while keeping $m = 20$. The results are shown in figure \ref{fig:performance1}.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/perf/mseplot_m(20-20)_e(6-12).png}
        \caption{Mean MSE of Test and Train sets.}
        \label{fig:mse1}
    \end{subfigure}
    \hfill %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/perf/errorplot_m(20-20)_e(6-12).png}
        \caption{Mean absolute difference of errors in class 0 and class 1 and mean percentage of errors in both classes, measured on test set.}
        \label{fig:errorplot1}
    \end{subfigure}
    \hfill %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/perf/errorbar_m(20-20)_e(6-12).png}
        \caption{Bar plot of mean percentage of errors in class 0 and class 1 measured on test set.}
        \label{fig:errorbar1}
    \end{subfigure}
    \caption{Performance of RBFN with parameters $m = 20$ and $\epsilon = 0.6,0.7, 0.8, 0.9, 1.0, 1.1, 1.2$, ran 10  times for each parameter combination.}\label{fig:performance1}
\end{figure}


Looking at figure \ref{fig:mse1} we see that MSE reaches a local minimum around $\epsilon = 0.9$ and at that point the test set MSE is lower than the training set MSE. After $\epsilon = 1$ it starts decreasing, which indicates we might be overfitting. Looking at \ref{fig:errorplot1}, we see that at $\epsilon = 0.8$ we get very low mean absolute difference in errors between the two classes. Furthermore, looking at \ref{fig:errorbar1} we see that at the same point the mean percentage of errors for both classes is around 1\% with a very small standard deviation. We choose $\epsilon = 0.8$ for our final architecture, as it  achieves a low MSE, a balance between errors in the two classes and a low variance in percentage of errors.


\subsection{Results}
%Give a synopsis of the results obtained from the final selected network.
%Relate these results back to the problem as stated – a MSE on its own
%is not helpful in judging how well something works.
%Identify anything of interest in the results, such as areas of particularly
%good or poor performance, or variation between different training runs.
The final chosen architecture achieves an average MSE of 0.025. In tables \ref{table:test_results} and \ref{table:train_results} the mean results for the training and test sets out of 20 runs of the architecture are shown. We can see that the distribution of errors in the two classes isn't as balanced as when we were performing experiments. This could mean that the experiments performed were insufficient. 
\begin{table}[h!]
\csvautotabular{../MeanTestResults.csv}
\caption{Mean test results for $m=20$, $\epsilon=0.8$ out of 20 runs.}
\label{table:test_results}
\end{table}

\begin{table}[h!]
\csvautotabular{../MeanTrainResults.csv}
\caption{Mean train results for $m=20$, $\epsilon=0.8$ out of 20 runs.}
\label{table:train_results}
\end{table}


On figure \ref{fig:accuracy} the confusion matrix ROC plot and error histograms are shown for a single run of the network.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/final/confmat.png}
        \caption{Confusion matrix.}
        \label{fig:confmat}
    \end{subfigure}
    \hfill %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/final/roc.png}
        \caption{ROC plot.}
        \label{fig:roc}
    \end{subfigure}
    \hfill %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
    %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[t]{0.32\textwidth}
        \includegraphics[width=\textwidth]{../figures/final/errhist.png}
        \caption{Error histogram.}
        \label{fig:errhist}
    \end{subfigure}
    \caption{Performance of RBFN with parameters $m = 20$ and $\epsilon = 0.6,0.7, 0.8, 0.9, 1.0, 1.1, 1.2$, ran 10  times for each parameter combination.}\label{fig:accuracy}
\end{figure}


From the confusion matrix we see that the network achieves 96.4\% accuracy with a relatively equal distribution of errors in both classes. The shape of the ROC plot indicates a good classifier. However, on the error histogram we see that there are a lot of errors at the far right of the plot. These errors indicate that the network wasn't even close to classifying some of the data points correctly. These maybe points located near a class boundary which are misclassified due to noise or outliers, which are not in range of any of the RBF spreads. We also notice that the network shows a relatively small MSE even with a very small hidden layer. This could mean that the data we have isn't representative of the problem. Comparing the performance of the RBFN to that of the models proposed in \cite{Candanedo2016} we see that we get approximately the same accuracy as the models which use the same input variables (Temperature,
Humidity, Light, CO2 and Humidity Ratio).


\part*{Section B}


\section{Building energy consumption prediction}
The problem of predicting energy consumption of a building can be very important for expense managment or for places where energy consumption goes up in colder months, while energy production goes down and a balance has to be established. A neural network can be used to solve this kind of problem. The chosen network is a Multilayer Perceptron. A similar problem solved with neural networks can be seen in \cite{khosravani2016comparison}.
\subsection{Technical features of architecture}
MLP is a feedforward, multilayer architecture consisting of one input layer, one output layer and one or more hidden layers. The input layer distributes the inputs. Each neuron in the hidden layers computes a weighted sum of inputs, applies an activation function and produces an output. Each layer is fully connected to the next one. The output layer produces the outputs. The MLP uses an error correction learning rule, where it minimises an error function defined by the difference of it's output and the desired output (typically the error function is mean squared error). The activation functions for all hidden layer neurons are either hyperbolic tangent functions or a sigmoid functions. In the case of regression, the output layer has a linear activation function. The training algorithm for MLP is backpropagation. It consists of a forward pass, where the network computes it's output and a backward pass, where the weights are adjusted. Weight changes at each layer are computed based on the local gradient of the next layer. The MLP partitions the feature space into regions (using straight lines in the 2D case and hyper planes in higher dimensions). 
\subsection{Suitability of the architecture for your application}
The multilayer perceptron is a universal approximator. Given the right architecture and enough data it can approximate any function. The training process is slow and has to be done before the network is deployed which is a drawback. MLP also requires a large amount of training data which needs to be representative of the problem. However, once deployed the network can produce outputs very quickly. MLP is suitable for this particular problem because there is already a lot of historical energy consumption data available to train the network. It might be susceptible to changes in building, depending on the data used as inputs. Data about lots of different buildings might be required in order to achieve good generalisation.
\subsection{Source of data, and how the network might be trained}
As mentioned already, there is plenty of historical data to train the network. Since the problem is time series prediction we will be using past energy consumption as inputs. Energy consumption is often dependant on the time of year, the first three input variables will be the energy consumption for the month before, this month and next month from last year (if we are predicting for July 2017, inputs are energy consumption for June, July, August 2016). We also take the average temperature from the weather forecast for these three past months as an input. Another sensible input value would be the energy efficiency score of the building(this might be country specific).

The network will be trained using backpropagation. The desired values are obtained from historical data from past years. The activation function of hidden layer neurons will be sigmoid, so normalizing input variables to the range 0-1 so they match the dynamic range of the activation function will speed up convergence. The input data will be split into training, validation and test sets (50/25/25). During training the error on the validation set will be monitored and used as a stopping criteria. Size and number of hidden layers need to be determined experimentally. If desired accuracy isn't achieved then regularisation can be used in the training. 
\subsection{How the network would handle significant changes to building or environment}
The energy consumption inputs of the network depend on the building, they were measured in. Changes in building might affect the performance of the network significantly. The data we use for training should cover the range of buildings and climate zones, where we want the network to be deployed afterwards. Alternatively the network can be retrained on redeployment. 

The energy efficiency input, as mentioned might be country specific and might have different ranges, or categories. We can overcome this by normalising the values for different scoring systems to the range 0-1. However the scales might differ in its criterion for determining energy efficiency(energy efficiency might mean one thing in the UK and another in the US, further research required on this). If this is the case the network won't generalise well in the different countries. If none of these approaches gives sensible results, more domain knowledge of the problem might be required, to select more suitable inputs. 


\section{Abnormality detection in the operation of HVAC systems}
Early detection of faults in an HVAC system could significantly decrease maintenance costs in a building. Research in abnormality detection of HVAC sensor data has previously shown good results \cite{Narayanaswamy2014}. Neural networks have previusly been used for abnormallity detection in other domains \cite{wrro89505}. We decide to apply the neural network architecture proposed in \cite{wrro89505} to the problem of abnormality detection in HVAC systems.
\subsection{Technical features of the architecture}
%The chosen architecture is a binary Correlation Matrix Memory. Binary CMMs are single layer neural network with binary inputs and weights, which use the Hebbian learning rule. They store associations between input and output patterns by setting the wights of connections, betweeen input bits equal to 1 and output bits equal to 1, to 1. Recall is done by multIn order to be used as a classifier the output of the CMM needs to be thresholded. 

Binary CMMs are single layer neural networks, which use the Hebbian learning rule. They consist of a single weight matrix which stores correlations between input and output patterns. Learning is done by computing the outer product of the binary input and output and adding it to the outer products of all other stored patterns to form the weight matrix. Recall of a stored pattern is done by multiplying the weight matrix and the input. The result from a recall is real valued. In order to obtain the associated binary output pattern, the output needs to be thresholded. A Wilshaw threshold is chosen for this architecture where each value in the recalled vector is compared to the number of bits, set to one in the input(1 if greater, zero otherwise). Real valued inputs need to be encoded. We do this by using a binning procedure, where we choose bins for certain ranges of the input and associate a binary pattern to that bin. After all inputs have been binned they are concatenated to form the input to the CMM. 
\subsection{Suitability of the architecture for your application}
A hardware implementation of a CMM can be very efficient. Store and recall are both very fast operations. This means we can monitor HVAC systems operation in real time and discover abnormal behaviour as soon as it occurs. This makes our chosen architecture very suitable for the particular problem.
\subsection{Source of data, and how the network might be trained}
The source of data will be sensors, part of the building management system, which monitor different aspects of the HVAC system operation. The sensor measurements we propose to use as inputs are energy consumption, airflow and supply water temperature. Sensors could be placed in every room in the building in order to help localise faults easier.  Sensor readings are taken at discrete time intervals to form our training input vectors. A significant amount of data might be required in order to achieve good generalisation and performance. Normal operation of the HVAC system can be monitored for 24 hours for 4 days of the year in different weather conditions. The network can be trained by applying the described binning and concatenation method to different input vectors and storing them in the CMM. Detecting abnormalities is done by recalling patterns in real time and comparing how similar they are to known patterns using for example a k-nearest neighbour algorithm. The tolerated level of similarity can be adjusted by using a smaller threshold at the outputs during recall and requires either domain knowledge or experimentation. 
\subsection{How the network would handle significant changes to building or environment}
The CMMs susceptibility to change of building or environment depends on the training examples. Given enough training data for different buildings in different environmental conditions the network will show good generalisation. On the other hand network can be trained over time by storing input patterns of normal operation which raise false alarms.

\bibliographystyle{ieeetr}
\bibliography{science}


\pagebreak
\appendix
\appendixpage


\lstset{language=Matlab,%
    %basicstyle=\color{red},
    breaklines=true,%
    morekeywords={matlab2tikz},
    keywordstyle=\color{blue},%
    morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
    identifierstyle=\color{black},%
    stringstyle=\color{mylilas},
    commentstyle=\color{mygreen},%
    showstringspaces=false,%without this there will be a symbol in the places where there is a space
    numbers=left,%
    numberstyle={\tiny \color{black}},% size of the numbers
    numbersep=9pt, % this defines how far the numbers are from the text
    frame = single,
    emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
    %emph=[2]{word1,word2}, emphstyle=[2]{style},    
}



\section{Data import script}
\lstinputlisting[caption=getData.m, label = listing:data]{../getData.m}

\pagebreak

\section{Network creation script}
\lstinputlisting[caption=RBFN.m, label = listing:rbfn]{../rbnet.m}

\pagebreak

\section{Network experimentation script}
\lstinputlisting[caption=runRBFN.m, label = listing:runrbfn]{../rbnetsearch.m}

\pagebreak

\section{Transformation settings}
\begin{table}[h]
\csvautotabular{../trans1.csv}
\caption{mapstd transformation settings}
\label{table:mapstd}
\end{table}

%\begin{table}[h]
%\csvautotabular[
%before reading = \begin{adjustbox}{max width=\columnwidth},
%after reading=\end{adjustbox},
%]{../trans2.csv}
%\caption{processpca transformation settings}
%\label{table:pca}
%\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|lllll|llll|}
\hline
properties        & \multicolumn{5}{c|}{transform}                       & \multicolumn{4}{c|}{inverseTransform}     \\ \hline
name = processpca & -0.37955 & -0.39547 & -0.40712 & -0.49929 & -0.53339 & -0.37955 & 0.52236  & 0.21998  & -0.69077 \\
xrows = 5         & 0.52236  & -0.58823 & 0.4643   & 0.10901  & -0.392   & -0.39547 & -0.58823 & 0.1784   & 0.065158 \\
maxfrac = 0.02    & 0.21998  & 0.1784   & 0.37132  & -0.85446 & 0.22761  & -0.40712 & 0.4643   & 0.37132  & 0.6934   \\
yrows = 4         & -0.69077 & 0.065158 & 0.6934   & 0.091391 & -0.17156 & -0.49929 & 0.10901  & -0.85446 & 0.091391 \\
nochange = 0      &          &          &          &          &          & -0.53339 & -0.392   & 0.22761  & -0.17156 \\ \hline
\end{tabular}%
}
\caption{processpca transformation settings}
\label{table:pca}
\end{table}


\section{Results from experimentation}
\begin{table}[!ht]
\csvautotabular{../MeanTestResults5-60.csv}
\caption{Test results for $m = 5,15,20,25,30,40,50,60$ and $\epsilon = 1$, 10 runs}
\label{table:res1}
\end{table}


\begin{table}[!ht]
\csvautotabular{../MeanTrainResults5-60.csv}
\caption{Train results for $m = 5,15,20,25,30,40,50,60$ and $\epsilon = 1$, 10 runs}
\label{table:res2}
\end{table}


\begin{table}[h]
\csvautotabular{../MeanTestResults6-12.csv}
\caption{Test results for $m = 20$ and $\epsilon = 0.6,0.7,0.8,0.9,1.0,1.1,1.2$, 10 runs}
\label{table:res3}
\end{table}


\begin{table}[h]
\csvautotabular{../MeanTrainResults6-12.csv}
\caption{Train results for $m = 20$ and $\epsilon = 0.6,0.7,0.8,0.9,1.0,1.1,1.2$, 10 runs}
\label{table:res4}
\end{table}

\end{document}
